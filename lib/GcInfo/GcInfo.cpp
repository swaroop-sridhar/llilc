//===-------- include/gcinfo/gcinfo.cpp -------------------------*- C++ -*-===//
//
// LLILC
//
// Copyright (c) Microsoft. All rights reserved.
// Licensed under the MIT license.
// See LICENSE file in the project root for full license information.
//
//===----------------------------------------------------------------------===//
///
/// \file
/// \brief Implements the generation of CLR GCTables in LLILC
///
//===----------------------------------------------------------------------===//

#include "earlyincludes.h"
#include "GcInfo.h"
#include "Target.h"
#include "llvm/ADT/DenseMap.h"
#include "llvm/ADT/SmallBitVector.h"
#include "llvm/Object/StackMapParser.h"
#include <sstream>

using namespace llvm;

GCInfo::GCInfo(LLILCJitContext *JitCtx, uint8_t *StackMapData,
               GcInfoAllocator *Allocator, size_t OffsetCor)
    : JitContext(JitCtx), LLVMStackMapData(StackMapData),
      OffsetCorrection(OffsetCor),
      Encoder(JitContext->JitInfo, JitContext->MethodInfo, Allocator) {
#if !defined(NDEBUG)
  this->EmitLogs = JitContext->Options->LogGcInfo;
#endif // !NDEBUG
#if defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
  this->CallSites = nullptr;
  this->CallSiteSizes = nullptr;
#endif // defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
}

void GCInfo::encodeHeader(const Function &F) {
#if !defined(NDEBUG)
  if (EmitLogs) {
    dbgs() << "GcTable for Function: " << F.getName() << "\n";
  }
#endif // !NDEBUG

  // TODO: Set Code Length accurately.
  // https://github.com/dotnet/llilc/issues/679
  // JitContext->HotCodeSize is the size of the allocated code block.
  // It is not the actual length of the current function's code.
  Encoder.SetCodeLength(JitContext->HotCodeSize);
#if !defined(NDEBUG)
  if (EmitLogs) {
    dbgs() << "  Size: " << JitContext->HotCodeSize << "\n";
  }
#endif // !NDEBUG

  if (isStackBaseFramePointer(F)) {
    Encoder.SetStackBaseRegister(REGNUM_FPBASE);
#if !defined(NDEBUG)
    if (EmitLogs) {
      dbgs() << "  StackBaseRegister: FP\n";
    }
#endif // !NDEBUG
  } else {
#if !defined(NDEBUG)
    if (EmitLogs) {
      dbgs() << "  StackBaseRegister: SP\n";
    }
#endif // !NDEBUG
  }

#if defined(FIXED_STACK_PARAMETER_SCRATCH_AREA)
  // TODO: Set size of outgoing/scratch area accurately
  // https://github.com/dotnet/llilc/issues/681
  const unsigned ScratchAreaSize = 0;
  Encoder.SetSizeOfStackOutgoingAndScratchArea(ScratchAreaSize);
#if !defined(NDEBUG)
  if (EmitLogs) {
    dbgs() << "  Scratch Area Size: " << ScratchAreaSize << "\n";
  }
#endif // !NDEBUG
#endif // defined(FIXED_STACK_PARAMETER_SCRATCH_AREA)
}

void GCInfo::encodeLiveness(const Function &F) {
  if (LLVMStackMapData == nullptr) {
    return;
  }

  ArrayRef<uint8_t> StackMapContentsArray(LLVMStackMapData,
                                          JitContext->StackMapSize);

#if defined(BIGENDIAN)
  typedef StackMapV1Parser<support::big> StackMapParserType;
#else
  typedef StackMapV1Parser<support::little> StackMapParserType;
#endif
  StackMapParserType StackMapParser(StackMapContentsArray);

  // TODO: Once StackMap v2 is implemented, remove this assertion about
  // one function per module, and emit the GcInfo for the records
  // corresponding to the Function 'F'
  assert(StackMapParser.getNumFunctions() == 1 &&
         "Expect only one function with GcInfo in the module");

// Loop over LLVM StackMap records to:
// 1) Note CallSites (safepoints)
// 2) Assign Slot-IDs to each unique gc-pointer location (slot)
// 3) Record liveness (birth/death) of slots per call-site.

#if defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
  NumCallSites = StackMapParser.getNumRecords();
  CallSites = new unsigned[NumCallSites];
  CallSiteSizes = new BYTE[NumCallSites];
#endif // defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)

  // TODO: Determine call-site-size accurately
  // https://github.com/Microsoft/llvm/issues/56
  // Call-site size is not available in LLVM's StackMap v1, so just make up
  // a value for now. The Call-instruction generated by LLILC on X86/X64
  // is typically Call [rax], which has a two-byte encoding.
  //
  // Any size > 0 can be reported as CallSizeSize, see explanation below.
  //
  // CoreCLR's API expects that we report:
  // (a) the offset at the beginning of the Call instruction, and
  // (b) size of the call instruction.
  //
  // LLVM's stackMap currently only reports:
  // (c) the offset at the safepoint after the call instruction (= a+b)
  //
  // When not in a fully-intrruptible block, CoreCLR only
  // uses the value of (a+b) to determine the end of the call
  // instruction. Therefore, we simply report a = c-2 and b = 2 for now.
  //
  // Once call-size size is available in LLVM StackMap v2, we can remove this
  // implementation specific workaround.

  const uint8_t CallSiteSize = 2;

  DenseMap<int32_t, GcSlotId> SlotMap;
  size_t NumSlots = 0;

  // LLVM StackMap records all live-pointers per Safepoint, whereas
  // CoreCLR's GCTables record pointer birth/deaths per Safepoint.
  // So, we do the translation using old/new live-pointer-sets
  // using bit-sets for recording the liveness -- one bit per slot.

  size_t LiveBitSetSize = 25;
  SmallBitVector OldLiveSet(LiveBitSetSize);
  SmallBitVector NewLiveSet(LiveBitSetSize);

  // TODO: Identify Object and Managed pointers differently
  // https://github.com/dotnet/llilc/issues/28
  // We currently conservatively describe all slots as containing
  // interior pointers
  const GcSlotFlags SlotFlags = (GcSlotFlags)GC_SLOT_INTERIOR;

#if !defined(NDEBUG)
  if (EmitLogs) {
    dbgs() << "  #Safepoints: " << StackMapParser.getNumRecords() << "\n";
  }

  std::ostringstream SlotStream;
  std::ostringstream LiveStream;
#endif // !NDEBUG

  size_t RecordIndex = 0;
  for (const auto &R : StackMapParser.records()) {

    // InstructionOffset:
    // + OffsetCorrection: to account for any bytes before the start
    //                     of the function.
    // - CallSiteSize: to report the start of the Instruction
    //
    // LLVM's Safepoint reports the offset at the end of the Call
    // instruction, whereas the CoreCLR API expects that we report
    // the start of the Call instruction.

    unsigned InstructionOffset =
        R.getInstructionOffset() + OffsetCorrection - CallSiteSize;

#if defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
    CallSites[RecordIndex] = InstructionOffset;
    CallSiteSizes[RecordIndex] = CallSiteSize;
#endif // defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)

#if !defined(NDEBUG)
    if (EmitLogs) {
      LiveStream << "    " << RecordIndex << ": @" << InstructionOffset;
    }
#endif // !NDEBUG

    // We don't generate GC_CALLER_SP_REL locatons, just
    // using this as a default value other than SP/FP REL.
    GcStackSlotBase SpBase = GC_CALLER_SP_REL;

    for (const auto &Loc : R.locations()) {

      switch (Loc.getKind()) {
      case StackMapParserType::LocationKind::Constant:
      case StackMapParserType::LocationKind::ConstantIndex:
        continue;

      case StackMapParserType::LocationKind::Register:
        // TODO: Report Live - GC values in Registers
        // https://github.com/dotnet/llilc/issues/474
        // Live gc-pointers are currently spilled to the stack at Safepoints.
        assert(false && "GC-Pointer Live in Register");
        break;

      case StackMapParserType::LocationKind::Direct: {
        uint16_t DwReg = Loc.getDwarfRegNum();
        switch (DwReg) {
        case DW_FRAME_POINTER:
          assert(SpBase != GC_SP_REL && "Mixed SP/FP based Locations");
          SpBase = GC_FRAMEREG_REL;
          break;
        case DW_STACK_POINTER:
          assert(SpBase != GC_FRAMEREG_REL && "Mixed SP/FP based Locations");
          SpBase = GC_SP_REL;
          break;
        default:
          assert(false && "Unexpected stack base-pointer");
        }

        GcSlotId SlotID;
        int32_t Offset = Loc.getOffset();
        DenseMap<int32_t, GcSlotId>::const_iterator ExistingSlot =
            SlotMap.find(Offset);
        if (ExistingSlot == SlotMap.end()) {
          SlotID = Encoder.GetStackSlotId(Offset, SlotFlags, SpBase);
          SlotMap[Offset] = SlotID;

          assert(SlotID == NumSlots && "SlotIDs dis-contiguous");
          NumSlots++;

          if (NumSlots > LiveBitSetSize) {
            LiveBitSetSize += LiveBitSetSize;

            assert(LiveBitSetSize > OldLiveSet.size() &&
                   "Overflow -- Too many live pointers");

            OldLiveSet.resize(LiveBitSetSize);
            NewLiveSet.resize(LiveBitSetSize);
          }

#if !defined(NDEBUG)
          if (EmitLogs) {
            SlotStream << "    [" << SlotID
                       << "]: " << ((SpBase == GC_SP_REL) ? "sp+" : "fp+")
                       << Offset << "\n";
          }
#endif // !NDEBUG
        } else {
          SlotID = ExistingSlot->second;
        }

        NewLiveSet[SlotID] = true;
        break;
      }

      default:
        assert(false && "Unexpected Location Type");
        break;
      }
    }

    // __LLVM_Stackmap reports the liveness of pointers wrt SP even for
    // certain methods which have a FP. So, we cannot
    // assert((SpBase == GC_FRAMEREG_REL) ?
    //          isStackBaseFramePointer(F) : !isStackBaseFramePointer(F));

    for (GcSlotId SlotID = 0; SlotID < NumSlots; SlotID++) {
      if (!OldLiveSet[SlotID] && NewLiveSet[SlotID]) {
#if !defined(NDEBUG)
        if (EmitLogs) {
          LiveStream << "  +" << SlotID;
        }
#endif // !NDEBUG
        Encoder.SetSlotState(InstructionOffset, SlotID, GC_SLOT_LIVE);
      } else if (OldLiveSet[SlotID] && !NewLiveSet[SlotID]) {
#if !defined(NDEBUG)
        if (EmitLogs) {
          LiveStream << "  -" << SlotID;
        }
#endif // !NDEBUG
        Encoder.SetSlotState(InstructionOffset, SlotID, GC_SLOT_DEAD);
      }

      OldLiveSet[SlotID] = NewLiveSet[SlotID];
      NewLiveSet[SlotID] = false;
    }

    RecordIndex++;

#if !defined(NDEBUG)
    if (EmitLogs) {
      LiveStream << "\n";
    }
#endif // !NDEBUG
  }

#if !defined(NDEBUG)
  if (EmitLogs) {
    dbgs() << "  Slots:\n" << SlotStream.str();
    dbgs() << "  Safepoints:\n" << LiveStream.str() << "\n";
  }
#endif // !NDEBUG

  // Finalize Slot IDs to enable compact representation
  Encoder.FinalizeSlotIds();

#if defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
  // Encode Call-sites
  Encoder.DefineCallSites(CallSites, CallSiteSizes, NumCallSites);
#endif // defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
}

void GCInfo::emitEncoding() {
  Encoder.Build();
  Encoder.Emit();
}

GCInfo::~GCInfo() {
#if defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
  delete CallSites;
  delete CallSiteSizes;
#endif // defined(PARTIALLY_INTERRUPTIBLE_GC_SUPPORTED)
}

void GCInfo::emitGCInfo(const Function &F) {
  encodeHeader(F);
  encodeLiveness(F);
  emitEncoding();
}

void GCInfo::emitGCInfo() {
  const Module::FunctionListType &FunctionList =
      JitContext->CurrentModule->getFunctionList();
  Module::const_iterator Iterator = FunctionList.begin();
  Module::const_iterator End = FunctionList.end();

  for (; Iterator != End; ++Iterator) {
    const Function &F = *Iterator;
    if (shouldEmitGCInfo(F)) {
      emitGCInfo(F);
    }
  }
}

bool GCInfo::shouldEmitGCInfo(const Function &F) {
  return !F.isDeclaration() && isGCFunction(F);
}

bool GCInfo::isGCFunction(const llvm::Function &F) {
  if (!F.hasGC()) {
    return false;
  }

  const StringRef CoreCLRName("coreclr");
  return (CoreCLRName == F.getGC());
}

bool GCInfo::isStackBaseFramePointer(const llvm::Function &F) {
  Attribute Attribute = F.getFnAttribute("no-frame-pointer-elim");
  return (Attribute.getValueAsString() == "true");
}
